{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"18ML9knJ7gD1JAVfZnaDtzCD8oAY2TQML","timestamp":1725332604841}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"YqUstTLMnhAC","executionInfo":{"status":"ok","timestamp":1725546130423,"user_tz":240,"elapsed":42767,"user":{"displayName":"Asheer Mogal","userId":"01179902760994344512"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"25981566-f725-47a9-80db-ffdbe6e7266a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyspark\n","  Downloading pyspark-3.5.2.tar.gz (317.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n","Building wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.5.2-py2.py3-none-any.whl size=317812365 sha256=5c76de2eb3d23b9bd892031f6f39527f7333caeb08d41722c48e0417c7e33658\n","  Stored in directory: /root/.cache/pip/wheels/34/34/bd/03944534c44b677cd5859f248090daa9fb27b3c8f8e5f49574\n","Successfully built pyspark\n","Installing collected packages: pyspark\n","Successfully installed pyspark-3.5.2\n","Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.5)\n","Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n"]}],"source":["!pip install pyspark\n","!pip install openpyxl\n","\n","import pandas as pd\n","import numpy as np\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col, lit, when\n","from pyspark.sql import SparkSession, functions as F"]},{"cell_type":"code","source":["# Initialize Spark Session\n","spark = SparkSession.builder \\\n","    .appName(\"Address Data Merging\") \\\n","    .getOrCreate()\n","\n","# Load DataFrames from CSV files\n","# TAKE THE CSV FILES WITHOUT THE ADDRESS COLUMNS EXCEPT THE GOOGLE STANDARD ADDRESS TO AVOID THE DELIMITER ISSUES\n","df_1945 = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv('/content/Copy of 1945_addresses_aggregated_repeated - Sheet1.csv')\n","df_1975 = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv('/content/Copy of 1975_addresses_aggregated_repeated - Sheet1.csv')\n","df_1985 = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv('/content/Copy of 1985_addresses_aggregated_repeated - Sheet1.csv')\n","\n","# Rename columns to 'standard_address' for uniform joining\n","df_1945 = df_1945.withColumnRenamed(\"google_standard_address_1945\", \"standard_address\")\n","df_1975 = df_1975.withColumnRenamed(\"google_standard_address_1975\", \"standard_address\")\n","df_1985 = df_1985.withColumnRenamed(\"google_standard_address_1985\", \"standard_address\")\n","\n","# Combine addresses into one DataFrame and remove duplicates\n","all_addresses = df_1945.select(\"standard_address\").union(df_1975.select(\"standard_address\")).union(df_1985.select(\"standard_address\")).distinct()\n","\n","# Perform left joins to merge all data based on 'standard_address'\n","df_merged_1945 = all_addresses.join(df_1945, \"standard_address\", \"left\")\n","df_merged_1975 = all_addresses.join(df_1975, \"standard_address\", \"left\")\n","df_merged_1985 = all_addresses.join(df_1985, \"standard_address\", \"left\")\n","\n","# Combine all dataframes into a final merged dataframe\n","df_combined = df_merged_1945.join(df_merged_1975, on=\"standard_address\", how=\"outer\")\n","df_final = df_combined.join(df_merged_1985, on=\"standard_address\", how=\"outer\")\n"],"metadata":{"id":"3cLts57kkwzK","colab":{"base_uri":"https://localhost:8080/","height":356},"executionInfo":{"status":"error","timestamp":1725545638550,"user_tz":240,"elapsed":10952,"user":{"displayName":"Asheer Mogal","userId":"01179902760994344512"}},"outputId":"ce729600-28ad-4bbb-887a-083b06e72f43"},"execution_count":null,"outputs":[{"output_type":"error","ename":"AnalysisException","evalue":"[PATH_NOT_FOUND] Path does not exist: file:/content/Copy of 1945_addresses_aggregated_repeated - Sheet1.csv.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-d59498647744>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Load DataFrames from CSV files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# TAKE THE CSV FILES WITHOUT THE ADDRESS COLUMNS EXCEPT THE GOOGLE STANDARD ADDRESS TO AVOID THE DELIMITER ISSUES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdf_1945\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"header\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inferSchema\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/Copy of 1945_addresses_aggregated_repeated - Sheet1.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mdf_1975\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"header\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inferSchema\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/Copy of 1975_addresses_aggregated_repeated - Sheet1.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdf_1985\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"header\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inferSchema\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/Copy of 1985_addresses_aggregated_repeated - Sheet1.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mcsv\u001b[0;34m(self, path, schema, sep, encoding, quote, escape, comment, header, inferSchema, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, nullValue, nanValue, positiveInf, negativeInf, dateFormat, timestampFormat, maxColumns, maxCharsPerColumn, maxMalformedLogPerPartition, mode, columnNameOfCorruptRecord, multiLine, charToEscapeQuoteEscaping, samplingRatio, enforceSchema, emptyValue, locale, lineSep, pathGlobFilter, recursiveFileLookup, modifiedBefore, modifiedAfter, unescapedQuoteHandling)\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoSeq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRDD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAnalysisException\u001b[0m: [PATH_NOT_FOUND] Path does not exist: file:/content/Copy of 1945_addresses_aggregated_repeated - Sheet1.csv."]}]},{"cell_type":"code","source":["# Convert the Spark DataFrame to a Pandas DataFrame\n","pandas_df = df_final.toPandas()\n","pandas_df.to_csv('final.csv')"],"metadata":{"id":"p8t_k19Nrbip"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Adding indicator columns for presence of data in each year\n","df_analysis = df_final.withColumn(\"present_1945\", F.col(\"ID_1945\").isNotNull()) \\\n","                       .withColumn(\"present_1975\", F.col(\"ID_1975\").isNotNull()) \\\n","                       .withColumn(\"present_1985\", F.col(\"ID_1985\").isNotNull())\n","\n","# Group by the presence indicators and count\n","address_presence_summary = df_analysis.groupBy(\"present_1945\", \"present_1975\", \"present_1985\").count()\n","\n","# Show the results\n","address_presence_summary.show()\n","\n","# Calculate specific categories based on the summary DataFrame\n","all_years = address_presence_summary.filter(\"present_1945 AND present_1975 AND present_1985\").collect()[0][\"count\"]\n","only_1945 = address_presence_summary.filter(\"present_1945 AND NOT present_1975 AND NOT present_1985\").collect()[0][\"count\"]\n","only_1975 = address_presence_summary.filter(\"NOT present_1945 AND present_1975 AND NOT present_1985\").collect()[0][\"count\"]\n","only_1985 = address_presence_summary.filter(\"NOT present_1945 AND NOT present_1975 AND present_1985\").collect()[0][\"count\"]\n","both_1945_1975 = address_presence_summary.filter(\"present_1945 AND present_1975 AND NOT present_1985\").collect()[0][\"count\"]\n","both_1975_1985 = address_presence_summary.filter(\"NOT present_1945 AND present_1975 AND present_1985\").collect()[0][\"count\"]\n","both_1985_1945 = address_presence_summary.filter(\"present_1945 AND NOT present_1975 AND present_1985\").collect()[0][\"count\"]\n","\n","# Print the counts\n","print(\"Addresses found in all years:\", all_years)\n","print(\"Addresses found only in 1945:\", only_1945)\n","print(\"Addresses found only in 1975:\", only_1975)\n","print(\"Addresses found only in 1985:\", only_1985)\n","print(\"Addresses found in both 1945 and 1975:\", both_1945_1975)\n","print(\"Addresses found in both 1975 and 1985:\", both_1975_1985)\n","print(\"Addresses found in both 1985 and 1945:\", both_1985_1945)\n"],"metadata":{"id":"ftx7tegS2WBo","colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"status":"error","timestamp":1725547540782,"user_tz":240,"elapsed":255,"user":{"displayName":"Asheer Mogal","userId":"01179902760994344512"}},"outputId":"e79d77b8-9cc5-4804-f389-78cd3ad144f7"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'df_final' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-45-a9e32fc94d8d>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Adding indicator columns for presence of data in each year\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_analysis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_final\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"present_1945\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ID_1945\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misNotNull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m                        \u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"present_1975\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ID_1975\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misNotNull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                        \u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"present_1985\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ID_1985\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misNotNull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'df_final' is not defined"]}]},{"cell_type":"code","source":["df = pd.read_csv('/content/common addresses new - final.csv')"],"metadata":{"id":"OEjeymAYj5SQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.columns"],"metadata":{"id":"jERpOV1PlVju","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725547496969,"user_tz":240,"elapsed":189,"user":{"displayName":"Asheer Mogal","userId":"01179902760994344512"}},"outputId":"c539b2ab-3a06-4245-e4e8-6cf9c153b048"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['standard_address', 'latitude', 'longitude', 'one_rep_ID1945',\n","       'ID_1945', 'people_1945', 'document_number_1945', 'parcel_number_1945',\n","       'original_grantee_city_or_town_1945', 'aceres_rendered_1945',\n","       'value_dollars_1945', 'designate_homestead_1945',\n","       'value_of_city_property_1945', 'value_of_personal_property_1945',\n","       'total_value_for_state_tax_1945', 'state_tax_1945', 'county_tax_1945',\n","       'district_school_1945', 'total_tax_1945', '2022_assessed_value_1945',\n","       'one_rep_ID1975', 'ID_1975', 'people_1975', 'document_number_1975',\n","       'original_grantee_city_or_town_1975', 'aceres_rendered_1975',\n","       'value_dollars_(state_value)_1975', 'designate_homestead_1975',\n","       'value_of_city_property_(total_county_value)_1975',\n","       'value_of_personal_property_1975', 'total_value_for_county_tax_1975',\n","       'state_tax_1975', 'county_tax_1975', 'district_school_1975',\n","       'tax_total_(including_hospital_and_water_taxes)_1975', 'one_rep_ID1985',\n","       'ID_1985', 'people_1985', 'folder_name_1985', 'document_number_1985',\n","       'area_1985', 'roll_seq_1985', 'land _1985', 'bld-val_1985',\n","       'spec_feat_1985', 'assessed_1985', 'homestead_1985', 'school_1985',\n","       'county_1985', 'city_1985', 'lbb_school_1985', 'lbb_city_1985',\n","       'L C H D_1985', 'county_1985.1', 'gross_tax_1985'],\n","      dtype='object')"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["df['commonA'] = 0"],"metadata":{"id":"uU_6qVtBke3Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# def fill_column(row):\n","#     # Check if all three are not null first\n","#     if pd.notna(row['one_rep_ID1945']) and pd.notna(row['one_rep_ID1975']) and pd.notna(row['one_rep_ID1985']):\n","#         return 4\n","#     elif pd.notna(row['one_rep_ID1945']) and pd.notna(row['one_rep_ID1975']):\n","#         return 1\n","#     elif pd.notna(row['one_rep_ID1975']) and pd.notna(row['one_rep_ID1985']):\n","#         return 3\n","#     elif pd.notna(row['one_rep_ID1985']) and pd.notna(row['one_rep_ID1945']):\n","#         return 2\n","\n","# # Assuming df is your Pandas DataFrame\n","# df['commonA'] = df.apply(fill_column, axis=1)\n","\n","\n","conditions = [\n","    (df['ID_1945'].notna() & df['ID_1985'].notna() & df['ID_1975'].notna()),  # All three are not NA\n","    (df['ID_1945'].notna() & df['ID_1985'].notna()),                          # 1945 and 1985 are not NA\n","    (df['ID_1945'].notna() & df['ID_1975'].notna()),                          # 1945 and 1975 are not NA\n","    (df['ID_1975'].notna() & df['ID_1985'].notna())                           # 1975 and 1985 are not NA\n","]\n","\n","choices = [4, 3, 2, 1]\n","\n","# Use np.select to apply conditions and choices\n","df['commonA'] = np.select(conditions, choices, default=0)"],"metadata":{"id":"lBrKf0UUk1IZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"All three IDs not null:\", (df['ID_1945'].notna() & df['ID_1985'].notna() & df['ID_1975'].notna()).sum())\n","print(\"ID_1945 and ID_1985 not null:\", (df['ID_1945'].notna() & df['ID_1985'].notna()).sum())\n","print(\"ID_1945 and ID_1975 not null:\", (df['ID_1945'].notna() & df['ID_1975'].notna()).sum())\n","print(\"ID_1975 and ID_1985 not null:\", (df['ID_1975'].notna() & df['ID_1985'].notna()).sum())\n"],"metadata":{"id":"ukdUKDdgryJ3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725548405931,"user_tz":240,"elapsed":227,"user":{"displayName":"Asheer Mogal","userId":"01179902760994344512"}},"outputId":"44851b64-6a74-4eec-e354-2e57451b4071"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["All three IDs not null: 314\n","ID_1945 and ID_1985 not null: 508\n","ID_1945 and ID_1975 not null: 889\n","ID_1975 and ID_1985 not null: 7189\n"]}]},{"cell_type":"code","source":["df.loc[(df['ID_1945'].notna() & df['ID_1985'].notna() & df['ID_1975'].notna()), 'commonA'] = 4\n","df.loc[(df['ID_1945'].notna() & df['ID_1985'].notna()), 'commonA'] = 3\n","df.loc[(df['ID_1945'].notna() & df['ID_1975'].notna()), 'commonA'] = 2\n","df.loc[(df['ID_1975'].notna() & df['ID_1985'].notna()), 'commonA'] = 1\n"],"metadata":{"id":"tCbrdRapsEIy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['commonA'] = 0\n","df.loc[(df['ID_1975'].notna() & df['ID_1985'].notna()) & df['ID_1945'].isna(), 'commonA'] = 1\n","df.loc[(df['ID_1945'].notna() & df['ID_1975'].notna()) & df['ID_1985'].isna(), 'commonA'] = 2\n","df.loc[(df['ID_1945'].notna() & df['ID_1985'].notna()) & df['ID_1975'].isna(), 'commonA'] = 3\n","df.loc[(df['ID_1945'].notna() & df['ID_1975'].notna() & df['ID_1985'].notna()), 'commonA'] = 4"],"metadata":{"id":"fiaecZFTtX-n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df[df['commonA'] == 4].to_csv('common_in_all.csv', index=False)"],"metadata":{"id":"uxzn16r-t3hn"},"execution_count":null,"outputs":[]}]}